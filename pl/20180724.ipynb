{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "off_train = pd.read_csv('E:/tianchi/ccf_offline_stage1_train.csv')\n",
    "off_test = pd.read_csv('E:/tianchi/ccf_offline_stage1_test_revised.csv')\n",
    "off_train = off_train.dropna(subset = ['Coupon_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "off_train['result'] = off_train[['Coupon_id', 'Date']].apply(lambda x: 1 if pd.notnull(x[0]) and pd.notnull(x[1]) else 0, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 用户有当天使用优惠券,Use_today"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_nan_drop = off_train.dropna(subset=['Date'])\n",
    "date_nan_drop = date_nan_drop.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "def Use(z):\n",
    "    if z.Date_received == z.Date:\n",
    "        return 1\n",
    "    else:\n",
    "        return np.NaN\n",
    "\n",
    "date_nan_drop['Use_today'] = date_nan_drop.apply(Use, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = date_nan_drop[['User_id', 'Use_today']]\n",
    "a = a.drop_duplicates(subset=['User_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "off_train = pd.merge(off_train, a, on = 'User_id', how = 'left')\n",
    "off_test = pd.merge(off_test, a, on = 'User_id', how = 'left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 只在一个商铺领取过优惠劵并且有消费记录,Use_One_Merchant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Consume_oneMerchant = date_nan_drop['Merchant_id'].groupby(date_nan_drop['User_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Consume_oneMerchant.count()\n",
    "a = a.reset_index()\n",
    "a = a.rename(columns={'Merchant_id':'Use_One_Merchant'})\n",
    "a['Use_One_Merchant'] = a.Use_One_Merchant.apply(lambda x:1 if x == 1 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "off_train = pd.merge(off_train, a, on = 'User_id', how = 'left')\n",
    "off_test = pd.merge(off_test, a, on = 'User_id', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_coupon = off_train[['User_id', 'Coupon_id']]\n",
    "# 利用User_id和Coupon_id两列对用户进性分组，并且计算每组的数目，并进行序号重置\n",
    "user_coupon_count = user_coupon.groupby(by=['User_id']).size().reset_index()\n",
    "# 重命名\n",
    "user_coupon_count.rename(columns={0:'Coupon_size'}, inplace=True)\n",
    "# 将筛选出来需要merge的列和原始的数据进行merge Coupon_size代表用户领取的优惠劵数目\n",
    "off_train = off_train.merge(user_coupon_count, on='User_id', how='inner')\n",
    "\n",
    "user_coupon = off_train[['User_id', 'result']]\n",
    "# 利用User_id和result两列对用户进性分组，并且计算每组的数目（这里相当于求和），并进行序号重置\n",
    "user_coupon_used_count = user_coupon.groupby(by=['User_id']).sum().reset_index()\n",
    "# 重命名 Consume_count用户使用了的优惠劵数目\n",
    "user_coupon_used_count.rename(columns={'result':'Conupon_have_used_count'}, inplace=True)\n",
    "# 将筛选出来需要merge的列和原始的数据进行merge\n",
    "off_train = off_train.merge(user_coupon_used_count, on='User_id', how='inner')\n",
    "\n",
    "# 为训练集添加Coupon_all_consume特征，标记那些领取优惠劵数目等于使用优惠劵数目\n",
    "off_train['Coupon_all_consume'] = off_train[['Conupon_have_used_count','Coupon_size']].apply(lambda x : 1 if x[0] == x[1] else 0, axis = 1)\n",
    "# 去掉产生的中间列\n",
    "off_train = off_train.drop(columns=['Coupon_size', 'Conupon_have_used_count'])\n",
    "# 提取需要的列好merge到测试集中\n",
    "off_train_coupon_all_consume = off_train[['User_id', 'Coupon_all_consume']]\n",
    "off_train_coupon_all_consume = off_train_coupon_all_consume.drop_duplicates(['User_id', 'Coupon_all_consume'])\n",
    "#为测试集添加Coupon_all_consume特征\n",
    "off_test = off_test.merge(off_train_coupon_all_consume, on='User_id', how='left')\n",
    "# 填充merge以后的空值为0\n",
    "off_test = off_test.fillna({'Coupon_all_consume':0})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_coupon = off_train[['User_id', 'Coupon_id','result']]\n",
    "# 利用User_id和result两列对用户进性分组，并且计算每组的数目，并进行序号重置\n",
    "user_coupon_count = user_coupon.groupby(by=['User_id','result']).size().reset_index()\n",
    "# 重命名\n",
    "user_coupon_count.rename(columns={0:'Coupon_size'}, inplace=True)\n",
    "# 筛选出领取次数为1并且未消费的\n",
    "user_coupon_count_1 = user_coupon_count[(user_coupon_count.Coupon_size == 1) & (user_coupon_count.result == 0)]\n",
    "# 去掉不需要merge的这一列，即result\n",
    "user_coupon_count_1 = user_coupon_count_1.drop(columns=['result'])\n",
    "\n",
    "# 训练集进行添加One_coupon_no_consume特征\n",
    "# 将筛选出来需要merge的列和原始的数据进行merge\n",
    "off_train = off_train.merge(user_coupon_count_1, on='User_id', how='left')\n",
    "#再次重命名\n",
    "off_train.rename(columns={'Coupon_size':'One_coupon_no_consume'}, inplace=True)\n",
    "# 填充merge以后的空值项为 0\n",
    "off_train = off_train.fillna({'One_coupon_no_consume':0})\n",
    "\n",
    "# 测试集添加One_coupon_no_consume特征\n",
    "off_test = off_test.merge(user_coupon_count_1, on='User_id', how='left')\n",
    "off_test.rename(columns={'Coupon_size':'One_coupon_no_consume'}, inplace=True)\n",
    "off_test = off_test.fillna({'One_coupon_no_consume':0})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#按用户对优惠券id和消费日期进行分组并计数，得到用户的优惠券消费次数\n",
    "User_Coupon_notna = off_train['Date'].groupby(off_train['User_id']).count()\n",
    "User_Coupon_notna = User_Coupon_notna.reset_index()\n",
    "User_Coupon_notna.rename(columns = {'Date' : 'Consume_count'}, inplace=True)\n",
    "\n",
    "#将得到的特征返回到训练集与测试集中，测试集中有训练集中没有出现的用户，这类用户的这个特征默认填了空，把空值填0\n",
    "off_train = pd.merge(off_train, User_Coupon_notna[['User_id', 'Consume_count']], on = ['User_id'], how = 'left')\n",
    "off_test = pd.merge(off_test, User_Coupon_notna[['User_id', 'Consume_count']], on = 'User_id', how = 'left')\n",
    "off_test = off_test.fillna(value = {'Consume_count' : 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#对训练集和测试集中的Discount_rate进行独热编码\n",
    "off_train = pd.get_dummies(off_train, prefix=['Discount_rate'])\n",
    "off_test = pd.get_dummies(off_test, prefix=['Discount_rate'])\n",
    "\n",
    "#训练集中出现了4个测试集中没有出现的码段，进行填充\n",
    "m = list(set(off_train.columns.tolist()) - set(off_test.columns.tolist()))\n",
    "for i in m:\n",
    "    off_test[i] = 0\n",
    "\n",
    "#测试集中有一个训练集中没有的码段，进行填充    \n",
    "off_train['Discount_rate_500:30'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "off_train.Distance = off_train.Distance.fillna(1)\n",
    "off_test.Distance = off_test.Distance.fillna(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "off_test = off_test.fillna(0)\n",
    "off_train = off_train.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#训练数据、训练标签、测试数据的设置\n",
    "x_train = off_train.drop(columns = ['Date_received', 'User_id', 'Merchant_id', 'Coupon_id', 'Date', 'result'])\n",
    "y_train = off_train.result\n",
    "x_test = off_test.drop(columns = ['Date_received', 'User_id', 'Merchant_id', 'Coupon_id'])\n",
    "\n",
    "#将训练数据和测试数据的列一一对应\n",
    "x_test = x_test[x_train.columns.tolist()]\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#调用逻辑回归模型，并进行训练\n",
    "clf = LogisticRegression()\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "#进行预测，并将需要保存的部分写入save\n",
    "predict = clf.predict_proba(x_test)\n",
    "save = off_test[['User_id', 'Coupon_id', 'Date_received']]\n",
    "save.insert(3, 'probability', predict[:,1], True)\n",
    "\n",
    "#输出结果为csv\n",
    "save.to_csv('E:/tianchi/20180725/Use_today_one_merchant.csv', index = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 计算5折交叉准确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.93537362, 0.93577237, 0.93502203, 0.93488436, 0.93451409])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "clf = LogisticRegression()\n",
    "cross_val_score(clf, x_train, y_train, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 抽取1/5数据做验证集，计算auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pulei\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9535294981847389"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import cross_validation,metrics\n",
    "\n",
    "train_x, test_x, train_y, test_y = cross_validation.train_test_split(x_train, y_train, test_size=0.2)#把训练集按0.2的比例划分为训练集和验证集\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(train_x, train_y)\n",
    "predict = clf.predict_proba(test_x)\n",
    "test_auc = metrics.roc_auc_score(test_y, predict[:,1])\n",
    "test_auc "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 画学习曲线"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
